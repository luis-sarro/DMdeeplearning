{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilidades de manipulación de imágenes y plantilla para arquitecturas de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Manipulado de imágenes\n",
    "\n",
    "Las siguiente funciones nos permiten recortar imágenes, de modo que se obtienen imágenes cuadradas, y generar conjuntos de entrenamiento y prueba que se almacenan en disco en una estructura de directorios que permiten a Keras interpretar a cada imagen en el tipo de conjunto al que pertenece (entrenamiento/prueba) y en la categoría o clase con la que se corresponde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from itertools import groupby\n",
    "from random import shuffle\n",
    "import os\n",
    "from keras.preprocessing.image import load_img, list_pictures\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "def cut_up_picture(p):\n",
    "    \"\"\"\n",
    "    Dada una imagen, devuelve los dos trozos \n",
    "    cuadrados más extremos de la misma.\n",
    "    \"\"\"\n",
    "    l = min(p.size)\n",
    "    p1 = p.crop((0, 0, l, l))\n",
    "    p2 = p.crop((p.width - l, p.height - l, p.width, p.height))\n",
    "    return p1, p2\n",
    "    \n",
    "def fold(pictures):\n",
    "    \"\"\"\n",
    "    Agrupa las imágenes originales en conjuntos\n",
    "    train y validation, cada una en su categoría \n",
    "    dentro de cada conjunto.\n",
    "    La selección la realiza de forma aleatoria, \n",
    "    según un 80%, 20%\n",
    "    \"\"\"\n",
    "    groups = groupby(pictures, lambda x: x.split(\"/\")[-1].split(\"_\")[0])\n",
    "    result = {'train':{},'validation':{}}\n",
    "    for k, g in groups:\n",
    "        g = list(g)\n",
    "        shuffle(g)\n",
    "        a = int(round(len(g) * 0.8))\n",
    "        result['train'][k] = g[:a]\n",
    "        result['validation'][k] = g[a:]\n",
    "    return result\n",
    "\n",
    "def create_data(folds):\n",
    "    \"\"\"\n",
    "    Crea los conjuntos de entrenamiento y validación\n",
    "    con imágenes cuadradas organizadas en directorios\n",
    "    directamente utilizables por Keras.\n",
    "    Las guarda en el directorio data.\n",
    "    \"\"\"\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data') \n",
    "    for k0,v0 in folds.iteritems():\n",
    "        if not os.path.exists('data/{}'.format(k0)):\n",
    "            os.makedirs('data/{}'.format(k0)) \n",
    "        for k1,v1 in v0.iteritems():\n",
    "            if not os.path.exists('data/{}/{}'.format(k0,k1)):\n",
    "                os.makedirs('data/{}/{}'.format(k0,k1))\n",
    "            for path in v1:\n",
    "                name = path.split(\"/\")[-1]\n",
    "                p0,p1 = cut_up_picture(load_img(path))\n",
    "                p0.save('data/{}/{}/0_{}'.format(k0,k1,name))\n",
    "                p0.save('data/{}/{}/1_{}'.format(k0,k1,name))\n",
    "\n",
    "def regenerate_all_data():\n",
    "    shutil.rmtree('data/train', ignore_errors=True)\n",
    "    os.makedirs('data/train')\n",
    "    shutil.rmtree('data/validation', ignore_errors=True)\n",
    "    os.makedirs('data/validation')\n",
    "    pictures = list_pictures('imagenesdepolen')\n",
    "    folds = fold(pictures)\n",
    "    create_data(folds)\n",
    "    \n",
    "\n",
    "# Sólo es necesario hacerlo una vez    \n",
    "# regenerate_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generadores de imágenes\n",
    "\n",
    "Una vez tenemos las imágenes en disco organizadas de una forma que Keras pueda interpretarlas automáticamente, según se ha descrito en el punto anterior, podeos definir los generados que alimenten el proceso de entrenamiento y prueba de la red automáticamente.\n",
    "\n",
    "Teniendo las imágenes organizadas según el punto anterior, y utilizando estos generadores, podemos centrarnos en las arquitecturas y no tener que dedicar más esfuerzo a la parte de la entrada de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1152 images belonging to 21 classes.\n",
      "Found 288 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 100, 100\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "#     save_to_dir='preview/train',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "#     save_to_dir='preview/validation',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "# Utilidad de visualización\n",
    "# Sólo si se activan los parámetros save_to_dir en los generadores\n",
    "\n",
    "# [os.remove('preview/train/' + f) for f in os.listdir('preview/train')]\n",
    "# [os.remove('preview/validation/' + f) for f in os.listdir('preview/validation')]\n",
    "# for batch in train_generator:\n",
    "#     break\n",
    "# for batch in validation_generator:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plantilla para arquitecturas con Keras\n",
    "\n",
    "Básicamente aquí se muestra un ejemplo de CNN diseñado con Keras y haciendo uso de los generadores anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "train_samples = 640\n",
    "validation_samples = 320\n",
    "\n",
    "# Pongo sólo 2 epochs simplemente para probar que todo\n",
    "# funciona bien. Cuando se intente entrenar una red de \n",
    "# verdad esto tendrá que ser más alto, quizá 50\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Entrenamiento sin monitorizar con TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10s - loss: -1.2329e+02 - acc: 0.0531 - val_loss: -1.4687e+02 - val_acc: 0.0437\n",
      "Epoch 2/2\n",
      "9s - loss: -1.5038e+02 - acc: 0.0406 - val_loss: -1.4642e+02 - val_acc: 0.0469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55ea5441d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=train_samples,\n",
    "    nb_epoch=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=validation_samples,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2. Entrenamiento monitorizando con TensorBoard\n",
    "\n",
    "En el caso de que se utilice TensorFlow como backend contra el que trabaja Keras, se puede monitorizar la evolución del entrenamiento de la red con TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "9s - loss: -1.4904e+02 - acc: 0.0516 - val_loss: -1.4986e+02 - val_acc: 0.0469\n",
      "Epoch 2/2\n",
      "8s - loss: -1.4508e+02 - acc: 0.0484 - val_loss: -1.4732e+02 - val_acc: 0.0469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55ea517690>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tb = TensorBoard(\n",
    "    log_dir='./logs', \n",
    "    histogram_freq=0, \n",
    "    write_graph=True, \n",
    "    write_images=False)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=train_samples,\n",
    "    nb_epoch=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=validation_samples,\n",
    "    verbose=2,\n",
    "    callbacks=[tb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Y evaluación del resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test score:', -141.98686218261719)\n",
      "('Test accuracy:', 0.078125)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(validation_generator, 50)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
