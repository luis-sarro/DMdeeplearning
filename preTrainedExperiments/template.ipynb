{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tunning de redes preentranadas\n",
    "\n",
    "Los experimentos realizados en este notebook se basan en las indicaciones de este [blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "\n",
    "La idea, básimente consiste en:\n",
    "1. coger una red ya entrenada previamente y quitarle la capa superior\n",
    "2. clarificar nuestro conjunto de datos con la red resultante del paso anterior\n",
    "3. diseñar un modelo sencillo cuyo input es el output del punto 2 y entrenarlo\n",
    "\n",
    "Aparentemente con muy poco cálculo se pueden obtener buenos resultados.\n",
    "\n",
    "En los siguientes experimentos voy a probar el planteamiento anterior utilizando las redes preentrenadas que vienen con defecto con Keras para ver cual de ellas ofrece mejores resultados.\n",
    "\n",
    "Después, una vez seleccionada una, intentaré determinar el optimizar el diseño del modelo superior.\n",
    "\n",
    "## Parámetros comunes para todos los experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import os.path\n",
    "\n",
    "\n",
    "train_data_dir = '../data/train'\n",
    "validation_data_dir = '../data/validation'\n",
    "\n",
    "train_features_path = '{}_train_features.npy'\n",
    "train_labels_path = '{}_train_labels.npy'\n",
    "validation_features_path = '{}_validation_features.npy'\n",
    "validation_labels_path = '{}_validation_labels.npy'\n",
    "weights_path = '{}_top_model.h5'\n",
    "\n",
    "# TODO: set properly\n",
    "width, height = 200, 200\n",
    "train_samples = 1152\n",
    "validation_samples = 288\n",
    "categories = 21\n",
    "batch_size = 4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de datos\n",
    "\n",
    "Definimos unas funciones que, dado un modelo preentrenado, permiten traducir nuestros datos en carácterísticas y etiquetas para utilizarse en el top model.\n",
    "\n",
    "Primero para los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_train_data_generated(name):\n",
    "    return os.path.isfile(train_features_path.format(name)) \\\n",
    "       and os.path.isfile(train_labels_path.format(name))\n",
    "\n",
    "def generate_train_data(name, model):\n",
    "    \n",
    "    naive_datagen = ImageDataGenerator(rescale=1. / 255)    \n",
    "    dataflow = naive_datagen.flow_from_directory(train_data_dir, \n",
    "                                                 batch_size=batch_size, \n",
    "                                                 class_mode='categorical',\n",
    "                                                 target_size=(width, height),\n",
    "                                                 shuffle=False)\n",
    "\n",
    "    features = None\n",
    "    labels = None    \n",
    "    rounds = train_samples // batch_size\n",
    "    print 'running {} rounds'.format(rounds)\n",
    "    for i in range(rounds):\n",
    "        if i % 50 == 0:\n",
    "            print\n",
    "            print i,'/',rounds,'.',\n",
    "        else:\n",
    "            print '.',\n",
    "        batch = dataflow.next()\n",
    "        batch_features = model.predict(batch[0])\n",
    "        batch_labels = batch[1]\n",
    "\n",
    "        if features is None:\n",
    "            features = batch_features\n",
    "        else:\n",
    "            features = np.append(features,batch_features,axis=0)\n",
    "\n",
    "        if labels is None:\n",
    "            labels = batch_labels\n",
    "        else:\n",
    "            labels = np.append(labels,batch_labels,axis=0)\n",
    "            \n",
    "    np.save(open(train_features_path.format(name), 'w'), features)\n",
    "    np.save(open(train_labels_path.format(name), 'w'), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora para los datos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_validation_data_generated(name):\n",
    "    return os.path.isfile(validation_features_path.format(name)) \\\n",
    "       and os.path.isfile(validation_labels_path.format(name))\n",
    "\n",
    "def generate_validation_data(name, model):\n",
    "    \n",
    "    naive_datagen = ImageDataGenerator(rescale=1. / 255)    \n",
    "    dataflow = naive_datagen.flow_from_directory(validation_data_dir, \n",
    "                                                 batch_size=batch_size, \n",
    "                                                 class_mode='categorical',\n",
    "                                                 target_size=(width, height),\n",
    "                                                 shuffle=False)\n",
    "\n",
    "    features = None\n",
    "    labels = None    \n",
    "    rounds = validation_samples // batch_size\n",
    "    print 'running {} rounds'.format(rounds)\n",
    "    for i in range(rounds):\n",
    "        if i % 50 == 0:\n",
    "            print\n",
    "            print i,'/',rounds,'.',\n",
    "        else:\n",
    "            print '.',\n",
    "        batch = dataflow.next()\n",
    "        batch_features = model.predict(batch[0])\n",
    "        batch_labels = batch[1]\n",
    "\n",
    "        if features is None:\n",
    "            features = batch_features\n",
    "        else:\n",
    "            features = np.append(features,batch_features,axis=0)\n",
    "\n",
    "        if labels is None:\n",
    "            labels = batch_labels\n",
    "        else:\n",
    "            labels = np.append(labels,batch_labels,axis=0)\n",
    "            \n",
    "    np.save(open(validation_features_path.format(name), 'w'), features)\n",
    "    np.save(open(validation_labels_path.format(name), 'w'), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una función que evita regerar datos ya generados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data_if_needed(name, model):\n",
    "    if not is_train_data_generated(name):\n",
    "        generate_train_data(name,model)\n",
    "        \n",
    "    if not is_validation_data_generated(name):\n",
    "        generate_validation_data(name,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top model común a todos los experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def common_top_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(categories, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutor de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(name, model):    \n",
    "    \n",
    "    print 'generating data if needed'\n",
    "    generate_data_if_needed(name, model)\n",
    "    \n",
    "    print 'loading train/validation data'    \n",
    "    train_features = np.load(open(train_features_path.format(name)))\n",
    "    train_labels = np.load(open(train_labels_path.format(name)))\n",
    "    validation_features = np.load(open(validation_features_path.format(name)))\n",
    "    validation_labels = np.load(open(validation_labels_path.format(name)))\n",
    "\n",
    "    print 'loaded shapes'\n",
    "    print '\\t',train_features.shape\n",
    "    print '\\t',train_labels.shape\n",
    "    print '\\t',validation_features.shape\n",
    "    print '\\t',validation_labels.shape\n",
    "              \n",
    "    print 'training top model'\n",
    "    top_model = common_top_model(train_features.shape[1:])\n",
    "    top_model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    top_model.fit(train_features,\n",
    "                  train_labels,\n",
    "                  batch_size=batch_size,\n",
    "                  nb_epoch=epochs,\n",
    "                  validation_data=(validation_features, validation_labels))\n",
    "              \n",
    "    print 'saving top model weights'\n",
    "    top_model.save_weights(weights_path.format(name))\n",
    "    print 'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG16_exp1():    \n",
    "    name = 'VGG16_exp1'       \n",
    "    VGG16 = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    run_experiment(name, VGG16)\n",
    "    \n",
    "# VGG16_exp1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El output de este experimento ha sido:\n",
    "```\n",
    "Using TensorFlow backend.\n",
    "training the top model\n",
    "(1152, 6, 6, 512)\n",
    "(1152, 21)\n",
    "(288, 6, 6, 512)\n",
    "(288, 21)\n",
    "Train on 1152 samples, validate on 288 samples\n",
    "Epoch 1/20\n",
    "1152/1152 [==============================] - 17s - loss: 3.7184 - acc: 0.2309 - val_loss: 1.5696 - val_acc: 0.5069\n",
    "Epoch 2/20\n",
    "1152/1152 [==============================] - 17s - loss: 1.7444 - acc: 0.4306 - val_loss: 1.1125 - val_acc: 0.6250\n",
    "Epoch 3/20\n",
    "1152/1152 [==============================] - 18s - loss: 1.4550 - acc: 0.5226 - val_loss: 0.8640 - val_acc: 0.6875\n",
    "Epoch 4/20\n",
    "1152/1152 [==============================] - 20s - loss: 1.1497 - acc: 0.6085 - val_loss: 0.9907 - val_acc: 0.7083\n",
    "Epoch 5/20\n",
    "1152/1152 [==============================] - 21s - loss: 1.0092 - acc: 0.6589 - val_loss: 0.6152 - val_acc: 0.7847\n",
    "Epoch 6/20\n",
    "1152/1152 [==============================] - 21s - loss: 0.9943 - acc: 0.6953 - val_loss: 0.5913 - val_acc: 0.7847\n",
    "Epoch 7/20\n",
    "1152/1152 [==============================] - 21s - loss: 0.8675 - acc: 0.7075 - val_loss: 0.7292 - val_acc: 0.7917\n",
    "Epoch 8/20\n",
    "1152/1152 [==============================] - 21s - loss: 0.8566 - acc: 0.7283 - val_loss: 0.5850 - val_acc: 0.8333\n",
    "Epoch 9/20\n",
    "1152/1152 [==============================] - 21s - loss: 0.7185 - acc: 0.7509 - val_loss: 1.2415 - val_acc: 0.7083\n",
    "Epoch 10/20\n",
    "1152/1152 [==============================] - 21s - loss: 0.6836 - acc: 0.7682 - val_loss: 0.9080 - val_acc: 0.7708\n",
    "Epoch 11/20\n",
    "1152/1152 [==============================] - 22s - loss: 0.7027 - acc: 0.7604 - val_loss: 0.7720 - val_acc: 0.7986\n",
    "Epoch 12/20\n",
    "1152/1152 [==============================] - 22s - loss: 0.6242 - acc: 0.8012 - val_loss: 0.6787 - val_acc: 0.8333\n",
    "Epoch 13/20\n",
    "1152/1152 [==============================] - 22s - loss: 0.5720 - acc: 0.8238 - val_loss: 0.7979 - val_acc: 0.7847\n",
    "Epoch 14/20\n",
    "1152/1152 [==============================] - 21s - loss: 0.5702 - acc: 0.8186 - val_loss: 1.0029 - val_acc: 0.7778\n",
    "Epoch 15/20\n",
    "1152/1152 [==============================] - 21s - loss: 0.5734 - acc: 0.8212 - val_loss: 0.6922 - val_acc: 0.8403\n",
    "Epoch 16/20\n",
    "1152/1152 [==============================] - 21s - loss: 0.4771 - acc: 0.8351 - val_loss: 1.0405 - val_acc: 0.7986\n",
    "Epoch 17/20\n",
    "1152/1152 [==============================] - 22s - loss: 0.5103 - acc: 0.8455 - val_loss: 0.9226 - val_acc: 0.7847\n",
    "Epoch 18/20\n",
    "1152/1152 [==============================] - 21s - loss: 0.4617 - acc: 0.8585 - val_loss: 0.8290 - val_acc: 0.8333\n",
    "Epoch 19/20\n",
    "1152/1152 [==============================] - 22s - loss: 0.4432 - acc: 0.8594 - val_loss: 0.7482 - val_acc: 0.8264\n",
    "Epoch 20/20\n",
    "1152/1152 [==============================] - 22s - loss: 0.5049 - acc: 0.8498 - val_loss: 0.9646 - val_acc: 0.7986\n",
    "```\n",
    "\n",
    "Es decir, en 5 minutos se obtiene un **val_acc: 0.8403**, cosa que encuentro muy prometedora.\n",
    "\n",
    "Siguientes pasos: probar con otras redes preentrenadas, quedarme con la que ofrezca el mejor resultado y con ella trabajar en el top model para optizarlo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
